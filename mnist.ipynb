{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requirements\n",
    "#!pip install torchdiffeq\n",
    "#!pip install POT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet2 import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ot as ot\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torchdiffeq import odeint_adjoint as odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"From https://github.com/atong01/conditional-flow-matching/blob/main/torchcfm/optimal_transport.py\"\"\"\n",
    "import math\n",
    "import warnings\n",
    "from functools import partial\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import ot as pot\n",
    "import torch\n",
    "\n",
    "\n",
    "class OTPlanSampler:\n",
    "    \"\"\"OTPlanSampler implements sampling coordinates according to an OT plan (wrt squared Euclidean\n",
    "    cost) with different implementations of the plan calculation.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        method: str,\n",
    "        reg: float = 0.05,\n",
    "        reg_m: float = 1.0,\n",
    "        normalize_cost: bool = False,\n",
    "        warn: bool = True,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize the OTPlanSampler class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        method: str\n",
    "            choose which optimal transport solver you would like to use.\n",
    "            Currently supported are [\"exact\", \"sinkhorn\", \"unbalanced\",\n",
    "            \"partial\"] OT solvers.\n",
    "        reg: float, optional\n",
    "            regularization parameter to use for Sinkhorn-based iterative solvers.\n",
    "        reg_m: float, optional\n",
    "            regularization weight for unbalanced Sinkhorn-knopp solver.\n",
    "        normalize_cost: bool, optional\n",
    "            normalizes the cost matrix so that the maximum cost is 1. Helps\n",
    "            stabilize Sinkhorn-based solvers. Should not be used in the vast\n",
    "            majority of cases.\n",
    "        warn: bool, optional\n",
    "            if True, raises a warning if the algorithm does not converge\n",
    "        \"\"\"\n",
    "        # ot_fn should take (a, b, M) as arguments where a, b are marginals and\n",
    "        # M is a cost matrix\n",
    "        if method == \"exact\":\n",
    "            self.ot_fn = pot.emd\n",
    "        elif method == \"sinkhorn\":\n",
    "            self.ot_fn = partial(pot.sinkhorn, reg=reg)\n",
    "        elif method == \"unbalanced\":\n",
    "            self.ot_fn = partial(pot.unbalanced.sinkhorn_knopp_unbalanced, reg=reg, reg_m=reg_m)\n",
    "        elif method == \"partial\":\n",
    "            self.ot_fn = partial(pot.partial.entropic_partial_wasserstein, reg=reg)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "        self.reg = reg\n",
    "        self.reg_m = reg_m\n",
    "        self.normalize_cost = normalize_cost\n",
    "        self.warn = warn\n",
    "\n",
    "    def get_map(self, x0, x1):\n",
    "        \"\"\"Compute the OT plan (wrt squared Euclidean cost) between a source and a target\n",
    "        minibatch.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x0 : Tensor, shape (bs, *dim)\n",
    "            represents the source minibatch\n",
    "        x1 : Tensor, shape (bs, *dim)\n",
    "            represents the source minibatch\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        p : numpy array, shape (bs, bs)\n",
    "            represents the OT plan between minibatches\n",
    "        \"\"\"\n",
    "        a, b = pot.unif(x0.shape[0]), pot.unif(x1.shape[0])\n",
    "        if x0.dim() > 2:\n",
    "            x0 = x0.reshape(x0.shape[0], -1)\n",
    "        if x1.dim() > 2:\n",
    "            x1 = x1.reshape(x1.shape[0], -1)\n",
    "        x1 = x1.reshape(x1.shape[0], -1)\n",
    "        M = torch.cdist(x0, x1) ** 2\n",
    "        if self.normalize_cost:\n",
    "            M = M / M.max()  # should not be normalized when using minibatches\n",
    "        p = self.ot_fn(a, b, M.detach().cpu().numpy())\n",
    "        if not np.all(np.isfinite(p)):\n",
    "            print(\"ERROR: p is not finite\")\n",
    "            print(p)\n",
    "            print(\"Cost mean, max\", M.mean(), M.max())\n",
    "            print(x0, x1)\n",
    "        if np.abs(p.sum()) < 1e-8:\n",
    "            if self.warn:\n",
    "                warnings.warn(\"Numerical errors in OT plan, reverting to uniform plan.\")\n",
    "            p = np.ones_like(p) / p.size\n",
    "        return p\n",
    "\n",
    "    def sample_map(self, pi, batch_size, replace=True):\n",
    "        r\"\"\"Draw source and target samples from pi  $(x,z) \\sim \\pi$\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        pi : numpy array, shape (bs, bs)\n",
    "            represents the source minibatch\n",
    "        batch_size : int\n",
    "            represents the OT plan between minibatches\n",
    "        replace : bool\n",
    "            represents sampling or without replacement from the OT plan\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (i_s, i_j) : tuple of numpy arrays, shape (bs, bs)\n",
    "            represents the indices of source and target data samples from $\\pi$\n",
    "        \"\"\"\n",
    "        p = pi.flatten()\n",
    "        p = p / p.sum()\n",
    "        choices = np.random.choice(\n",
    "            pi.shape[0] * pi.shape[1], p=p, size=batch_size, replace=replace\n",
    "        )\n",
    "        return np.divmod(choices, pi.shape[1])\n",
    "\n",
    "    def sample_plan(self, x0, x1, replace=True):\n",
    "        r\"\"\"Compute the OT plan $\\pi$ (wrt squared Euclidean cost) between a source and a target\n",
    "        minibatch and draw source and target samples from pi $(x,z) \\sim \\pi$\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x0 : Tensor, shape (bs, *dim)\n",
    "            represents the source minibatch\n",
    "        x1 : Tensor, shape (bs, *dim)\n",
    "            represents the source minibatch\n",
    "        replace : bool\n",
    "            represents sampling or without replacement from the OT plan\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x0[i] : Tensor, shape (bs, *dim)\n",
    "            represents the source minibatch drawn from $\\pi$\n",
    "        x1[j] : Tensor, shape (bs, *dim)\n",
    "            represents the source minibatch drawn from $\\pi$\n",
    "        \"\"\"\n",
    "        pi = self.get_map(x0, x1)\n",
    "        i, j = self.sample_map(pi, x0.shape[0], replace=replace)\n",
    "        return x0[i], x1[j]\n",
    "\n",
    "    def sample_plan_with_labels(self, x0, x1, y0=None, y1=None, replace=True):\n",
    "        r\"\"\"Compute the OT plan $\\pi$ (wrt squared Euclidean cost) between a source and a target\n",
    "        minibatch and draw source and target labeled samples from pi $(x,z) \\sim \\pi$\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x0 : Tensor, shape (bs, *dim)\n",
    "            represents the source minibatch\n",
    "        x1 : Tensor, shape (bs, *dim)\n",
    "            represents the target minibatch\n",
    "        y0 : Tensor, shape (bs)\n",
    "            represents the source label minibatch\n",
    "        y1 : Tensor, shape (bs)\n",
    "            represents the target label minibatch\n",
    "        replace : bool\n",
    "            represents sampling or without replacement from the OT plan\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x0[i] : Tensor, shape (bs, *dim)\n",
    "            represents the source minibatch drawn from $\\pi$\n",
    "        x1[j] : Tensor, shape (bs, *dim)\n",
    "            represents the target minibatch drawn from $\\pi$\n",
    "        y0[i] : Tensor, shape (bs, *dim)\n",
    "            represents the source label minibatch drawn from $\\pi$\n",
    "        y1[j] : Tensor, shape (bs, *dim)\n",
    "            represents the target label minibatch drawn from $\\pi$\n",
    "        \"\"\"\n",
    "        pi = self.get_map(x0, x1)\n",
    "        i, j = self.sample_map(pi, x0.shape[0], replace=replace)\n",
    "        return (\n",
    "            x0[i],\n",
    "            x1[j],\n",
    "            y0[i] if y0 is not None else None,\n",
    "            y1[j] if y1 is not None else None,\n",
    "        )\n",
    "\n",
    "    def sample_trajectory(self, X):\n",
    "        \"\"\"Compute the OT trajectories between different sample populations moving from the source\n",
    "        to the target distribution.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Tensor, (bs, times, *dim)\n",
    "            different populations of samples moving from the source to the target distribution.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        to_return : Tensor, (bs, times, *dim)\n",
    "            represents the OT sampled trajectories over time.\n",
    "        \"\"\"\n",
    "        times = X.shape[1]\n",
    "        pis = []\n",
    "        for t in range(times - 1):\n",
    "            pis.append(self.get_map(X[:, t], X[:, t + 1]))\n",
    "\n",
    "        indices = [np.arange(X.shape[0])]\n",
    "        for pi in pis:\n",
    "            j = []\n",
    "            for i in indices[-1]:\n",
    "                j.append(np.random.choice(pi.shape[1], p=pi[i] / pi[i].sum()))\n",
    "            indices.append(np.array(j))\n",
    "\n",
    "        to_return = []\n",
    "        for t in range(times):\n",
    "            to_return.append(X[:, t][indices[t]])\n",
    "        to_return = np.stack(to_return, axis=1)\n",
    "        return to_return\n",
    "\n",
    "\n",
    "def wasserstein(\n",
    "    x0: torch.Tensor,\n",
    "    x1: torch.Tensor,\n",
    "    method: Optional[str] = None,\n",
    "    reg: float = 0.05,\n",
    "    power: int = 2,\n",
    "    **kwargs,\n",
    ") -> float:\n",
    "    \"\"\"Compute the Wasserstein (1 or 2) distance (wrt Euclidean cost) between a source and a target\n",
    "    distributions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x0 : Tensor, shape (bs, *dim)\n",
    "        represents the source minibatch\n",
    "    x1 : Tensor, shape (bs, *dim)\n",
    "        represents the source minibatch\n",
    "    method : str (default : None)\n",
    "        Use exact Wasserstein or an entropic regularization\n",
    "    reg : float (default : 0.05)\n",
    "        Entropic regularization coefficients\n",
    "    power : int (default : 2)\n",
    "        power of the Wasserstein distance (1 or 2)\n",
    "    Returns\n",
    "    -------\n",
    "    ret : float\n",
    "        Wasserstein distance\n",
    "    \"\"\"\n",
    "    assert power == 1 or power == 2\n",
    "    # ot_fn should take (a, b, M) as arguments where a, b are marginals and\n",
    "    # M is a cost matrix\n",
    "    if method == \"exact\" or method is None:\n",
    "        ot_fn = pot.emd2\n",
    "    elif method == \"sinkhorn\":\n",
    "        ot_fn = partial(pot.sinkhorn2, reg=reg)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "    a, b = pot.unif(x0.shape[0]), pot.unif(x1.shape[0])\n",
    "    if x0.dim() > 2:\n",
    "        x0 = x0.reshape(x0.shape[0], -1)\n",
    "    if x1.dim() > 2:\n",
    "        x1 = x1.reshape(x1.shape[0], -1)\n",
    "    M = torch.cdist(x0, x1)\n",
    "    if power == 2:\n",
    "        M = M**2\n",
    "    ret = ot_fn(a, b, M.detach().cpu().numpy(), numItermax=int(1e7))\n",
    "    if power == 2:\n",
    "        ret = math.sqrt(ret)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implements Conditional Flow Matcher Losses. From https://github.com/atong01/conditional-flow-matching/blob/main/torchcfm/conditional_flow_matching.py\"\"\"\n",
    "\n",
    "# Author: Alex Tong\n",
    "#         Kilian Fatras\n",
    "#         +++\n",
    "# License: MIT License\n",
    "\n",
    "import math\n",
    "import warnings\n",
    "from typing import Union\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def pad_t_like_x(t, x):\n",
    "    \"\"\"Function to reshape the time vector t by the number of dimensions of x.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : Tensor, shape (bs, *dim)\n",
    "        represents the source minibatch\n",
    "    t : FloatTensor, shape (bs)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    t : Tensor, shape (bs, number of x dimensions)\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    x: Tensor (bs, C, W, H)\n",
    "    t: Vector (bs)\n",
    "    pad_t_like_x(t, x): Tensor (bs, 1, 1, 1)\n",
    "    \"\"\"\n",
    "    if isinstance(t, (float, int)):\n",
    "        return t\n",
    "    return t.reshape(-1, *([1] * (x.dim() - 1)))\n",
    "\n",
    "\n",
    "class ConditionalFlowMatcher:\n",
    "    \"\"\"Base class for conditional flow matching methods. This class implements the independent\n",
    "    conditional flow matching methods from [1] and serves as a parent class for all other flow\n",
    "    matching methods.\n",
    "\n",
    "    It implements:\n",
    "    - Drawing data from gaussian probability path N(t * x1 + (1 - t) * x0, sigma) function\n",
    "    - conditional flow matching ut(x1|x0) = x1 - x0\n",
    "    - score function $\\nabla log p_t(x|x0, x1)$\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sigma: Union[float, int] = 0.0):\n",
    "        r\"\"\"Initialize the ConditionalFlowMatcher class. It requires the hyper-parameter $\\sigma$.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sigma : Union[float, int]\n",
    "        \"\"\"\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def compute_mu_t(self, x0, x1, t):\n",
    "        \"\"\"\n",
    "        Compute the mean of the probability path N(t * x1 + (1 - t) * x0, sigma), see (Eq.14) [1].\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x0 : Tensor, shape (bs, *dim)\n",
    "            represents the source minibatch\n",
    "        x1 : Tensor, shape (bs, *dim)\n",
    "            represents the target minibatch\n",
    "        t : FloatTensor, shape (bs)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        mean mu_t: t * x1 + (1 - t) * x0\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [1] Improving and Generalizing Flow-Based Generative Models with minibatch optimal transport, Preprint, Tong et al.\n",
    "        \"\"\"\n",
    "        t = pad_t_like_x(t, x0)\n",
    "        return t * x1 + (1 - t) * x0\n",
    "\n",
    "    def compute_sigma_t(self, t):\n",
    "        \"\"\"\n",
    "        Compute the standard deviation of the probability path N(t * x1 + (1 - t) * x0, sigma), see (Eq.14) [1].\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        t : FloatTensor, shape (bs)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        standard deviation sigma\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [1] Improving and Generalizing Flow-Based Generative Models with minibatch optimal transport, Preprint, Tong et al.\n",
    "        \"\"\"\n",
    "        del t\n",
    "        return self.sigma\n",
    "\n",
    "    def sample_xt(self, x0, x1, t, epsilon):\n",
    "        \"\"\"\n",
    "        Draw a sample from the probability path N(t * x1 + (1 - t) * x0, sigma), see (Eq.14) [1].\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x0 : Tensor, shape (bs, *dim)\n",
    "            represents the source minibatch\n",
    "        x1 : Tensor, shape (bs, *dim)\n",
    "            represents the target minibatch\n",
    "        t : FloatTensor, shape (bs)\n",
    "        epsilon : Tensor, shape (bs, *dim)\n",
    "            noise sample from N(0, 1)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        xt : Tensor, shape (bs, *dim)\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [1] Improving and Generalizing Flow-Based Generative Models with minibatch optimal transport, Preprint, Tong et al.\n",
    "        \"\"\"\n",
    "        mu_t = self.compute_mu_t(x0, x1, t)\n",
    "        sigma_t = self.compute_sigma_t(t)\n",
    "        sigma_t = pad_t_like_x(sigma_t, x0)\n",
    "        return mu_t + sigma_t * epsilon\n",
    "\n",
    "    def compute_conditional_flow(self, x0, x1, t, xt):\n",
    "        \"\"\"\n",
    "        Compute the conditional vector field ut(x1|x0) = x1 - x0, see Eq.(15) [1].\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x0 : Tensor, shape (bs, *dim)\n",
    "            represents the source minibatch\n",
    "        x1 : Tensor, shape (bs, *dim)\n",
    "            represents the target minibatch\n",
    "        t : FloatTensor, shape (bs)\n",
    "        xt : Tensor, shape (bs, *dim)\n",
    "            represents the samples drawn from probability path pt\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ut : conditional vector field ut(x1|x0) = x1 - x0\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [1] Improving and Generalizing Flow-Based Generative Models with minibatch optimal transport, Preprint, Tong et al.\n",
    "        \"\"\"\n",
    "        del t, xt\n",
    "        return x1 - x0\n",
    "\n",
    "    def sample_noise_like(self, x):\n",
    "        return torch.randn_like(x)\n",
    "\n",
    "    def sample_location_and_conditional_flow(self, x0, x1, t=None, return_noise=False):\n",
    "        \"\"\"\n",
    "        Compute the sample xt (drawn from N(t * x1 + (1 - t) * x0, sigma))\n",
    "        and the conditional vector field ut(x1|x0) = x1 - x0, see Eq.(15) [1].\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x0 : Tensor, shape (bs, *dim)\n",
    "            represents the source minibatch\n",
    "        x1 : Tensor, shape (bs, *dim)\n",
    "            represents the target minibatch\n",
    "        (optionally) t : Tensor, shape (bs)\n",
    "            represents the time levels\n",
    "            if None, drawn from uniform [0,1]\n",
    "        return_noise : bool\n",
    "            return the noise sample epsilon\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        t : FloatTensor, shape (bs)\n",
    "        xt : Tensor, shape (bs, *dim)\n",
    "            represents the samples drawn from probability path pt\n",
    "        ut : conditional vector field ut(x1|x0) = x1 - x0\n",
    "        (optionally) eps: Tensor, shape (bs, *dim) such that xt = mu_t + sigma_t * epsilon\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [1] Improving and Generalizing Flow-Based Generative Models with minibatch optimal transport, Preprint, Tong et al.\n",
    "        \"\"\"\n",
    "        if t is None:\n",
    "            t = torch.rand(x0.shape[0]).type_as(x0)\n",
    "        assert len(t) == x0.shape[0], \"t has to have batch size dimension\"\n",
    "\n",
    "        eps = self.sample_noise_like(x0)\n",
    "        xt = self.sample_xt(x0, x1, t, eps)\n",
    "        ut = self.compute_conditional_flow(x0, x1, t, xt)\n",
    "        if return_noise:\n",
    "            return t, xt, ut, eps\n",
    "        else:\n",
    "            return t, xt, ut\n",
    "\n",
    "    def compute_lambda(self, t):\n",
    "        \"\"\"Compute the lambda function, see Eq.(23) [3].\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        t : FloatTensor, shape (bs)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        lambda : score weighting function\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [4] Simulation-free Schrodinger bridges via score and flow matching, Preprint, Tong et al.\n",
    "        \"\"\"\n",
    "        sigma_t = self.compute_sigma_t(t)\n",
    "        return 2 * sigma_t / (self.sigma**2 + 1e-8)\n",
    "\n",
    "\n",
    "class ExactOptimalTransportConditionalFlowMatcher(ConditionalFlowMatcher):\n",
    "    \"\"\"Child class for optimal transport conditional flow matching method. This class implements\n",
    "    the OT-CFM methods from [1] and inherits the ConditionalFlowMatcher parent class.\n",
    "\n",
    "    It overrides the sample_location_and_conditional_flow.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sigma: Union[float, int] = 0.0):\n",
    "        r\"\"\"Initialize the ConditionalFlowMatcher class. It requires the hyper-parameter $\\sigma$.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sigma : Union[float, int]\n",
    "        ot_sampler: exact OT method to draw couplings (x0, x1) (see Eq.(17) [1]).\n",
    "        \"\"\"\n",
    "        super().__init__(sigma)\n",
    "        self.ot_sampler = OTPlanSampler(method=\"exact\")\n",
    "\n",
    "    def sample_location_and_conditional_flow(self, x0, x1, t=None, return_noise=False):\n",
    "        r\"\"\"\n",
    "        Compute the sample xt (drawn from N(t * x1 + (1 - t) * x0, sigma))\n",
    "        and the conditional vector field ut(x1|x0) = x1 - x0, see Eq.(15) [1]\n",
    "        with respect to the minibatch OT plan $\\Pi$.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x0 : Tensor, shape (bs, *dim)\n",
    "            represents the source minibatch\n",
    "        x1 : Tensor, shape (bs, *dim)\n",
    "            represents the target minibatch\n",
    "        (optionally) t : Tensor, shape (bs)\n",
    "            represents the time levels\n",
    "            if None, drawn from uniform [0,1]\n",
    "        return_noise : bool\n",
    "            return the noise sample epsilon\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        t : FloatTensor, shape (bs)\n",
    "        xt : Tensor, shape (bs, *dim)\n",
    "            represents the samples drawn from probability path pt\n",
    "        ut : conditional vector field ut(x1|x0) = x1 - x0\n",
    "        (optionally) epsilon : Tensor, shape (bs, *dim) such that xt = mu_t + sigma_t * epsilon\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [1] Improving and Generalizing Flow-Based Generative Models with minibatch optimal transport, Preprint, Tong et al.\n",
    "        \"\"\"\n",
    "        x0, x1 = self.ot_sampler.sample_plan(x0, x1)\n",
    "        return super().sample_location_and_conditional_flow(x0, x1, t, return_noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Stolen from https://github.com/cfinlay/ffjord-rnode/blob/master/lib/layers/odefunc.py\"\"\"\n",
    "\n",
    "def divergence_approx(f, y, e=None):\n",
    "\n",
    "    samples = []\n",
    "    sqnorms = []\n",
    "    for  e_ in e:\n",
    "        e_dzdx = torch.autograd.grad(f, y, e_, create_graph=True)[0]\n",
    "        n = e_dzdx.view(y.size(0),-1).pow(2).mean(dim=1, keepdim=True)\n",
    "        sqnorms.append(n)\n",
    "        e_dzdx_e = e_dzdx * e_\n",
    "        samples.append(e_dzdx_e.view(y.shape[0], -1).sum(dim=1, keepdim=True))\n",
    "\n",
    "    S = torch.cat(samples, dim=1)\n",
    "    approx_tr_dzdx = S.mean(dim=1)\n",
    "\n",
    "    N = torch.cat(sqnorms, dim=1).mean(dim=1)\n",
    "\n",
    "\n",
    "    return approx_tr_dzdx, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Augmented ODE to train RNODE\"\"\"\n",
    "class regularized_Augmented_ODE2(nn.Module):\n",
    "    def __init__(self, ode_func: nn.Module):\n",
    "        super().__init__()\n",
    "        self.odefunc = ode_func\n",
    "\n",
    "    def forward(self, t, states):\n",
    "\n",
    "        z = states[0]         \n",
    "        with torch.set_grad_enabled(True):\n",
    "            z.requires_grad_(True)                                          #dynamics \n",
    "            dz_dt = self.odefunc(t, z)\n",
    "            epsilon = torch.randn_like(z)\n",
    "            dlog_det_dt, dn_dt = divergence_approx(dz_dt, z, e=epsilon.unsqueeze(0))\n",
    "            dE_dt = (torch.linalg.matrix_norm(dz_dt)**2)          #kinetic Energy\n",
    "\n",
    "            \"\"\"            \n",
    "            print(\"dz_dt: \", dz_dt.shape)\n",
    "            print(\"dlog_det_dt: \", dlog_det_dt.shape)\n",
    "            print(\"dE_dt: \", dE_dt.shape)\n",
    "            print(\"dn_dt: \", dn_dt.shape)\n",
    "            \"\"\"\n",
    "            return (dz_dt, dlog_det_dt, dE_dt, dn_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dynamics, i.e., right hand side of the ODE\"\"\"\n",
    "class NODE(nn.Module):\n",
    "    def __init__(self, convnet):\n",
    "        super().__init__()\n",
    "        self.net = convnet\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        return self.net(t, x)\n",
    "    \n",
    "    \"\"\"plots the ode solutions from its initial value x at time 0 to the final solution at time 1 (t decides number of steps)\"\"\"\n",
    "    def plot_trajectories(self, trajectories=None, t=None, x=None):\n",
    "        fig, ax = plt.subplots()\n",
    "        with torch.no_grad():\n",
    "            if trajectories == None:\n",
    "                trajectories = odeint(self, x, t, method=\"rk4\")\n",
    "\n",
    "            ax.plot(trajectories[:,:,0], trajectories[:,:,1], color=\"silver\", alpha=.7, zorder=0, label=\"flow\")            \n",
    "            ax.scatter(trajectories[0,:,0],trajectories[0,:,1], c=\"royalblue\", s=1, label=\"prior sample\", zorder=1)\n",
    "            ax.scatter(trajectories[-1,:,0], trajectories[-1,:,1], c=\"darkorange\", s=1, label=\"gen sample\", zorder=1)\n",
    "\n",
    "            handles, labels = plt.gca().get_legend_handles_labels()\n",
    "            by_label = dict(zip(labels, handles))\n",
    "            plt.legend(by_label.values(), by_label.keys())\n",
    "        \n",
    "        return fig, ax\n",
    "    \n",
    "    \"\"\"log probability of the model with a normal gaussian as the initial distribution\"\"\"\n",
    "    def log_probability(self, t, x):\n",
    "        initial_distr = torch.distributions.MultivariateNormal(torch.zeros(28), torch.eye(28))\n",
    "\n",
    "        l0 = torch.zeros((x.size(0),1), requires_grad=False)\n",
    "        initial_values = (x, l0)\n",
    "\n",
    "        augmented_dynamics = trace_Augmented_ODE(self)\n",
    "\n",
    "        z_t, log_det = odeint(augmented_dynamics, initial_values, t, method=\"rk4\")\n",
    "\n",
    "        logp_x = initial_distr.log_prob(z_t[-1]) + log_det[-1]\n",
    "\n",
    "        return -logp_x.mean()\n",
    "    \n",
    "    \"\"\"computes the average length of the trajectories from the initial values x to the values at the final timestep\"\"\"\n",
    "    def length_trajectories(self, trajectories=None, t=None, x=None):\n",
    "        with torch.no_grad():\n",
    "            if trajectories == None:\n",
    "                trajectories = odeint(self, x, t, method=\"rk4\")\n",
    "            distances = torch.linalg.norm(trajectories[1:] - trajectories[:-1], dim=-1)\n",
    "            length = distances.sum(dim=0)\n",
    "\n",
    "            return length.mean()\n",
    "        \n",
    "    \"computes the Wasserstein2 distance between samples generated from the initial values x and samples y from the true distribution\"\n",
    "    def wasserstein2_distance(self, y, trajectories=None, t=None, x=None):\n",
    "        with torch.no_grad():\n",
    "            if trajectories == None:\n",
    "                trajectories = odeint(self, x, t, method=\"rk4\")\n",
    "            z = trajectories[-1]\n",
    "            a, b = ot.unif(z.size(0)), ot.unif(y.size(0))\n",
    "            cost = torch.cdist(z, y) ** 2\n",
    "            distance = ot.emd2(a, b, cost.numpy())\n",
    "\n",
    "            return distance**.5\n",
    "\n",
    "    \n",
    "\"\"\"Augmented ODE for CNF without any regularization and choice of samples for the Hutchinson trace estimator and no gradient\"\"\"\n",
    "class trace_Augmented_ODE(nn.Module):\n",
    "    def __init__(self, ode_func: nn.Module):\n",
    "        super().__init__()\n",
    "        self.odefunc = ode_func\n",
    "\n",
    "    def forward(self, t, states):\n",
    "        with torch.no_grad():\n",
    "            z = states[0]\n",
    "            dz_dt, dlogp_z_dt =  self.hutchinson_trace_estimator(t, z)\n",
    "            return (dz_dt, dlogp_z_dt)\n",
    "        \n",
    "    def hutchinson_trace_estimator(self, t, z, samples=20):\n",
    "        trace = 0\n",
    "        \n",
    "        for _ in range(samples):\n",
    "            epsilon = torch.randn_like(z)\n",
    "            output_f, vjp_f = torch.autograd.functional.vjp(self.odefunc, (t,z), v=epsilon, create_graph=False)\n",
    "            trace +=  (vjp_f[1]*epsilon).sum(1).unsqueeze(1)    \n",
    "\n",
    "        return output_f, trace/samples\n",
    "    \n",
    "\"\"\"Augmented ODE to train NODE\"\"\"\n",
    "class Augmented_ODE(nn.Module):\n",
    "    def __init__(self, ode_func: nn.Module):\n",
    "        super().__init__()\n",
    "        self.odefunc = ode_func\n",
    "\n",
    "    def forward(self, t, states):\n",
    "        with torch.set_grad_enabled(True):\n",
    "            z = states[0]                                                               #dynamics \n",
    "            dz_dt, vjp_f, epsilon = self.vjp(self.odefunc, t, z)\n",
    "            dlog_det_dt =  (vjp_f*epsilon).sum(-1).sum(-1)                     #log-det of the Jacobian   \n",
    "            \n",
    "            return (dz_dt, dlog_det_dt)\n",
    "\n",
    "    def vjp(self, f, t, z):\n",
    "        \"\"\"computes vector Jacobian product and returns (output of the function, vjp, epsilon)\"\"\"\n",
    "        epsilon = torch.randn_like(z)\n",
    "        output_f, vjp_f = torch.autograd.functional.vjp(f, (t,z), v=epsilon, create_graph=True)\n",
    "        return output_f, vjp_f[1], epsilon\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Augmented ODE to train RNODE\"\"\"\n",
    "class regularized_Augmented_ODE(nn.Module):\n",
    "    def __init__(self, ode_func: nn.Module):\n",
    "        super().__init__()\n",
    "        self.odefunc = ode_func\n",
    "\n",
    "    def forward(self, t, states):\n",
    "        with torch.set_grad_enabled(True):\n",
    "            z = states[0]                                                               #dynamics \n",
    "            dz_dt, vjp_f, epsilon = self.vjp(self.odefunc, t, z)\n",
    "            dlog_det_dt =  (vjp_f*epsilon).sum(-1).sum(-1)                     #log-det of the Jacobian   \n",
    "            dE_dt = (torch.linalg.matrix_norm(dz_dt)**2)          #kinetic Energy\n",
    "            dn_dt = (torch.linalg.matrix_norm(vjp_f)**2)          #Frobenius norm of the Jacobian\n",
    "\n",
    "            \"\"\"            \n",
    "            print(\"dz_dt: \", dz_dt.shape)\n",
    "            print(\"dlog_det_dt: \", dlog_det_dt.shape)\n",
    "            print(\"dE_dt: \", dE_dt.shape)\n",
    "            print(\"dn_dt: \", dn_dt.shape)\n",
    "            \"\"\"\n",
    "            return (dz_dt, dlog_det_dt, dE_dt, dn_dt)\n",
    "\n",
    "    def vjp(self, f, t, z):\n",
    "        \"\"\"computes vector Jacobian product and returns (output of the function, vjp, epsilon)\"\"\"\n",
    "        epsilon = torch.randn_like(z)\n",
    "        output_f, vjp_f = torch.autograd.functional.vjp(f, (t,z), v=epsilon, create_graph=True)\n",
    "        return output_f, vjp_f[1], epsilon\n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\"computes the loss of RNODE, given the dynamics 'model' and samples 'x'\"\"\"\n",
    "def rnode_loss(model: torch.nn.Module, x, lambda_k: float, lambda_j: float):\n",
    "    initial_distr = torch.distributions.MultivariateNormal(torch.zeros(28), torch.eye(28))\n",
    "    t = torch.linspace(0, 1, 5).type(torch.float32)\n",
    "    l0 = torch.zeros((x.size(0),1), requires_grad=True)\n",
    "    kin_E0 = torch.zeros((x.size(0),1), requires_grad=True)\n",
    "    n0 = torch.zeros((x.size(0),1), requires_grad=True)\n",
    "    initial_values = (x, l0, kin_E0, n0)\n",
    "\n",
    "    augmented_dynamics = regularized_Augmented_ODE(model)\n",
    "\n",
    "    z_t, log_det, E_t, n_t = odeint(augmented_dynamics, initial_values, t,\n",
    "                                    method=\"rk4\")\n",
    "\n",
    "    z1, l1, kin_E1, n1 = z_t[-1], log_det[-1], E_t[-1], n_t[-1]\n",
    "\n",
    "    logp_x = initial_distr.log_prob(z1) + l1 - lambda_k * kin_E1 - lambda_j * n1\n",
    "    loss = -logp_x.mean()\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnode_training(epochs, seed, learning_rate, lambda_k, lambda_j):\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    model = UNet(\n",
    "            input_channels=1,\n",
    "            input_height=28,\n",
    "            ch=32,\n",
    "            ch_mult=(1, 2,4),\n",
    "            num_res_blocks=2,\n",
    "            attn_resolutions=(16,),\n",
    "            resamp_with_conv=True,\n",
    "            dropout=0,\n",
    "            )\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    initial_distr = torch.distributions.MultivariateNormal(torch.zeros(28), torch.eye(28))\n",
    "    start = time.time()\n",
    "    Path(\"mnist/rnode/models\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Epoch {epoch + 1}/{epochs}')\n",
    "        num = 0\n",
    "        for i, (samples, labels) in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            #samples.requires_grad = True\n",
    "\n",
    "            x0 = samples\n",
    "            \n",
    "            t = torch.linspace(1, 0, 5).type(torch.float32)\n",
    "            l0 = torch.zeros((x0.size(0),1), requires_grad=True)\n",
    "            kin_E0 = torch.zeros((x0.size(0),1), requires_grad=True)\n",
    "            n0 = torch.zeros((x0.size(0),1), requires_grad=True)\n",
    "            initial_values = (x0, l0, kin_E0, n0)\n",
    "\n",
    "            augmented_dynamics = regularized_Augmented_ODE(model)\n",
    "\n",
    "            z_t, log_det, E_t, n_t = odeint(augmented_dynamics, initial_values, t, method=\"dopri5\", rtol=1e-5, atol=1e-5)\n",
    "            print(\"yay\")\n",
    "            z1, l1, kin_E1, n1 = z_t[-1], log_det[-1], E_t[-1], n_t[-1]\n",
    "\n",
    "            logp_x = initial_distr.log_prob(z1) + l1 - lambda_k * kin_E1 - lambda_j * n1\n",
    "            loss = -logp_x.mean()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss\n",
    "            num += 1\n",
    "        \n",
    "        torch.save(model.state_dict(), os.path.join(\"mnist/rnode/models\", f\"{epoch}_model.pt\"))\n",
    "        print(f\"\\nloss: {loss/num}\")\n",
    "        \n",
    "\n",
    "    print(\"finished training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Training loop for OT-CFM\"\"\"\n",
    "def cfm_training(epochs, seed, learning_rate, sigma):\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    model = UNet(\n",
    "            input_channels=1,\n",
    "            input_height=28,\n",
    "            ch=32,\n",
    "            ch_mult=(1, 2,4),\n",
    "            num_res_blocks=2,\n",
    "            attn_resolutions=(16,),\n",
    "            resamp_with_conv=True,\n",
    "            dropout=0,\n",
    "            )\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    FM = ExactOptimalTransportConditionalFlowMatcher(sigma=sigma)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    start = time.time()\n",
    "    Path(\"mnist/cfm/models\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Epoch {epoch + 1}/{epochs}')\n",
    "        num = 0\n",
    "        for i, (samples, labels) in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x0 = torch.randn_like(samples)\n",
    "            t, xt, ut = FM.sample_location_and_conditional_flow(x0, samples)\n",
    "            vt = model(t, xt)\n",
    "            loss = torch.mean((vt - ut) ** 2)\n",
    "            loss.backward()\n",
    "            #print(loss)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss\n",
    "            num += 1\n",
    "        \n",
    "        torch.save(model.state_dict(), os.path.join(\"mnist/cfm/models\", f\"{epoch}_model.pt\"))\n",
    "        print(f\"\\nloss: {epoch_loss/num}\")\n",
    "        \n",
    "\n",
    "    print(\"finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hyperparameters_and_metrics(file_path: str, hyperparameters: dict, metrics: dict):\n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(\"Hyperparameters:\\n\")\n",
    "        for param, value in hyperparameters.items():\n",
    "            file.write(f\"{param}: {value}\\n\")\n",
    "\n",
    "        file.write(\"\\nMetrics per  batches:\\n\")\n",
    "        file.write(\"batches, loss, negative_log_likelihood, flow_length, wasserstein2_distance, elapsed_time\\n\")\n",
    "        for  batches in range(len(metrics[\"batches\"])):\n",
    "            file.write(f\"{metrics['batches'][batches]}, {metrics['loss'][batches]}, {metrics['log_probability'][batches]}, {metrics['flow_length'][batches]}, {metrics['wasserstein2_distance'][batches]}, {metrics['elapsed_time'][batches]}\\n\")\n",
    "        \n",
    "        file.write(f\"total time: {sum(metrics['elapsed_time'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 128\n",
    "n_epochs = 10\n",
    "learning_rate=1e-3\n",
    "seed = 44\n",
    "lambda_k = .1\n",
    "lambda_j = .1\n",
    "sigma = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cfm_training(n_epochs, seed, learning_rate, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/469 [05:22<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[150], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrnode_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_j\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[145], line 49\u001b[0m, in \u001b[0;36mrnode_training\u001b[0;34m(epochs, seed, learning_rate, lambda_k, lambda_j)\u001b[0m\n\u001b[1;32m     46\u001b[0m logp_x \u001b[38;5;241m=\u001b[39m initial_distr\u001b[38;5;241m.\u001b[39mlog_prob(z1) \u001b[38;5;241m+\u001b[39m l1 \u001b[38;5;241m-\u001b[39m lambda_k \u001b[38;5;241m*\u001b[39m kin_E1 \u001b[38;5;241m-\u001b[39m lambda_j \u001b[38;5;241m*\u001b[39m n1\n\u001b[1;32m     47\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mlogp_x\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m---> 49\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     52\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/autograd/function.py:301\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m     )\n\u001b[1;32m    300\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torchdiffeq/_impl/adjoint.py:134\u001b[0m, in \u001b[0;36mOdeintAdjointMethod.backward\u001b[0;34m(ctx, *grad_y)\u001b[0m\n\u001b[1;32m    131\u001b[0m     time_vjps[i] \u001b[38;5;241m=\u001b[39m dLd_cur_t\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Run the augmented system backwards in time.\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m aug_state \u001b[38;5;241m=\u001b[39m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maugmented_dynamics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maug_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madjoint_rtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madjoint_atol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madjoint_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madjoint_options\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m aug_state \u001b[38;5;241m=\u001b[39m [a[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m aug_state]  \u001b[38;5;66;03m# extract just the t[i - 1] value\u001b[39;00m\n\u001b[1;32m    140\u001b[0m aug_state[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m y[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# update to use our forward-pass estimate of the state\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torchdiffeq/_impl/odeint.py:79\u001b[0m, in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     76\u001b[0m solver \u001b[38;5;241m=\u001b[39m SOLVERS[method](func\u001b[38;5;241m=\u001b[39mfunc, y0\u001b[38;5;241m=\u001b[39my0, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     solution \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     event_t, solution \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mintegrate_until_event(t[\u001b[38;5;241m0\u001b[39m], event_fn)\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torchdiffeq/_impl/solvers.py:34\u001b[0m, in \u001b[0;36mAdaptiveStepsizeODESolver.integrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_integrate(t)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(t)):\n\u001b[0;32m---> 34\u001b[0m     solution[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_advance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solution\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torchdiffeq/_impl/rk_common.py:227\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._advance\u001b[0;34m(self, next_t)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m next_t \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m n_steps \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_num_steps exceeded (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_steps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps)\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adaptive_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrk_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     n_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _interp_evaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39minterp_coeff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt0, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1, next_t)\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torchdiffeq/_impl/rk_common.py:292\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._adaptive_step\u001b[0;34m(self, rk_state)\u001b[0m\n\u001b[1;32m    287\u001b[0m         dt \u001b[38;5;241m=\u001b[39m t1 \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# Must be arranged as doing all the step_t handling, then all the jump_t handling, in case we\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# trigger both. (i.e. interleaving them would be wrong.)\u001b[39;00m\n\u001b[0;32m--> 292\u001b[0m y1, f1, y1_error, k \u001b[38;5;241m=\u001b[39m \u001b[43m_runge_kutta_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtableau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtableau\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# dtypes:\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# y1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# f1.dtype == self.y0.dtype\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m#                     Error Ratio                      #\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m########################################################\u001b[39;00m\n\u001b[1;32m    302\u001b[0m error_ratio \u001b[38;5;241m=\u001b[39m _compute_error_ratio(y1_error, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrtol, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matol, y0, y1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm)\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torchdiffeq/_impl/rk_common.py:78\u001b[0m, in \u001b[0;36m_runge_kutta_step\u001b[0;34m(func, y0, f0, t0, dt, t1, tableau)\u001b[0m\n\u001b[1;32m     76\u001b[0m         perturb \u001b[38;5;241m=\u001b[39m Perturb\u001b[38;5;241m.\u001b[39mNONE\n\u001b[1;32m     77\u001b[0m     yi \u001b[38;5;241m=\u001b[39m y0 \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(k[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m (beta_i \u001b[38;5;241m*\u001b[39m dt), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mview_as(f0)\n\u001b[0;32m---> 78\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mti\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperturb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     k \u001b[38;5;241m=\u001b[39m _UncheckedAssign\u001b[38;5;241m.\u001b[39mapply(k, f, (\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (tableau\u001b[38;5;241m.\u001b[39mc_sol[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (tableau\u001b[38;5;241m.\u001b[39mc_sol[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m tableau\u001b[38;5;241m.\u001b[39mbeta[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mall()):\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# This property (true for Dormand-Prince) lets us save a few FLOPs.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torchdiffeq/_impl/misc.py:197\u001b[0m, in \u001b[0;36m_PerturbFunc.forward\u001b[0;34m(self, t, y, perturb)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Do nothing.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torchdiffeq/_impl/misc.py:165\u001b[0m, in \u001b[0;36m_ReverseFunc.forward\u001b[0;34m(self, t, y)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, t, y):\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmul \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torchdiffeq/_impl/misc.py:144\u001b[0m, in \u001b[0;36m_TupleFunc.forward\u001b[0;34m(self, t, y)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, t, y):\n\u001b[0;32m--> 144\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_flat_to_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshapes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat([f_\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m f_ \u001b[38;5;129;01min\u001b[39;00m f])\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torchdiffeq/_impl/adjoint.py:94\u001b[0m, in \u001b[0;36mOdeintAdjointMethod.backward.<locals>.augmented_dynamics\u001b[0;34m(t, y_aug)\u001b[0m\n\u001b[1;32m     91\u001b[0m     _y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_strided(y, (), ())  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     _params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(torch\u001b[38;5;241m.\u001b[39mas_strided(param, (), ()) \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m adjoint_params)  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     vjp_t, vjp_y, \u001b[38;5;241m*\u001b[39mvjp_params \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43madjoint_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43madj_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# autograd.grad returns None if no gradient, set to zero.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m vjp_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(t) \u001b[38;5;28;01mif\u001b[39;00m vjp_t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m vjp_t\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:412\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    408\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    409\u001b[0m         grad_outputs_\n\u001b[1;32m    410\u001b[0m     )\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    423\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    425\u001b[0m     ):\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnode_training(n_epochs, seed, learning_rate, lambda_k, lambda_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3189737d0>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model = UNet(\n",
    "            input_channels=1,\n",
    "            input_height=28,\n",
    "            ch=32,\n",
    "            ch_mult=(1, 2,4),\n",
    "            num_res_blocks=2,\n",
    "            attn_resolutions=(16,),\n",
    "            resamp_with_conv=True,\n",
    "            dropout=0,\n",
    "            )\n",
    "model.load_state_dict(torch.load(\"mnist/cfm/models/0_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "samples = next(iter(test_loader))[0][0].unsqueeze(0)\n",
    "a = torch.randn_like(samples)\n",
    "\n",
    "print(samples.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    gen = odeint(model, a, torch.linspace(0, 1, 20).type(torch.float32), method=\"dopri5\")\n",
    "\n",
    "b = gen[-1,0,0]\n",
    "#print(a[0,0]==b)\n",
    "plt.imshow(b, cmap=\"gray\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
