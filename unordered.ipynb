{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requirements\n",
    "#!pip install torchdyn\n",
    "#!pip install torchdiffeq\n",
    "#!pip install POT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ot as ot\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "from torchdyn.datasets import generate_gaussians, generate_moons, generate_concentric_spheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Data Sampler and utils\"\"\"\n",
    "\n",
    "def sample_normal(n, mu=torch.zeros(2), sigma=1):\n",
    "    distr = torch.distributions.MultivariateNormal(mu, sigma*torch.eye(2))\n",
    "    return distr.sample((n,))\n",
    "\n",
    "def sample_gaussians(n, n_gaussians=7):\n",
    "    num = int(n/n_gaussians)+1\n",
    "    x0, _ = generate_gaussians(num, n_gaussians, radius=4, std_gaussians=.5)\n",
    "    return x0[:n]\n",
    "\n",
    "def sample_moons(n):\n",
    "    x0, _ = generate_moons(n, noise=0.2)\n",
    "    return x0 * 4 - 2\n",
    "\n",
    "def sample_circles(n):\n",
    "    x0, _ = generate_concentric_spheres(n , dim=2, inner_radius=.5, outer_radius=1)\n",
    "    return x0\n",
    "\n",
    "class sampler():\n",
    "    def __init__(self, dataset: str):\n",
    "        if dataset == \"normal\":\n",
    "            self.sampler = sample_normal\n",
    "        elif dataset == \"gaussians\":\n",
    "            self.sampler = sample_gaussians\n",
    "        elif dataset == \"moons\":\n",
    "            self.sampler = sample_moons\n",
    "        elif dataset == \"circles\":\n",
    "            self.sampler = sample_circles\n",
    "        else:\n",
    "            raise Exception(\"Selected Dataset not supported. Choose between normal, gaussians, moons or circles\")\n",
    "\n",
    "    def __call__(self, n: int):\n",
    "        return self.sampler(n)\n",
    "\n",
    "\"\"\"utils\"\"\"\n",
    "def initial_setup(x, y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(x[:,0],x[:,1], c=\"royalblue\", s=1, label=\"initial dataset\")\n",
    "    ax.scatter(y[:,0], y[:,1], c=\"darkorange\", s=1, label=\"target dataset\")\n",
    "    ax.set_title(\"initial and target distributions\")\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "def save_hyperparameters_and_metrics(file_path: str, hyperparameters: dict, metrics: dict):\n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(\"Hyperparameters:\\n\")\n",
    "        for param, value in hyperparameters.items():\n",
    "            file.write(f\"{param}: {value}\\n\")\n",
    "\n",
    "        file.write(\"\\nMetrics per  batches:\\n\")\n",
    "        file.write(\"batches, loss, negative_log_likelihood, flow_length, wasserstein2_distance, elapsed_time\\n\")\n",
    "        for  batches in range(len(metrics[\"batches\"])):\n",
    "            file.write(f\"{metrics['batches'][batches]}, {metrics['loss'][batches]}, {metrics['log_probability'][batches]}, {metrics['flow_length'][batches]}, {metrics['wasserstein2_distance'][batches]}, {metrics['elapsed_time'][batches]}\\n\")\n",
    "        \n",
    "        file.write(f\"total time: {sum(metrics['elapsed_time'])}\")\n",
    "\n",
    "def test_model(model_path: str, seed=44, samples=5):\n",
    "    a = model_path.split(\"/\")\n",
    "    b = a[3]\n",
    "    a = (a[1]).split(\"_\")\n",
    "    a.remove(\"to\")\n",
    "\n",
    "    model = MLP()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    if a[0]==\"cfm\":\n",
    "        str_model_type, initial, target = a\n",
    "        kin, frob = None, None\n",
    "\n",
    "    else:\n",
    "        str_model_type, target, kin, frob = a\n",
    "        initial = \"normal\"\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    initial_samples = sampler(initial)\n",
    "    target_samples = sampler(target)\n",
    "\n",
    "\n",
    "\n",
    "    log_probability = 0\n",
    "    flow_length = 0\n",
    "    wasserstein2_distance = 0\n",
    "\n",
    "    for _ in range(samples):\n",
    "        X = initial_samples(1000)\n",
    "        Y = target_samples(1000)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            trajectories = odeint(model, X, torch.linspace(1, 0, 100), method=\"rk4\")\n",
    "            log_probability += model.log_probability(torch.linspace(0, 1, 5), Y).item()\n",
    "            flow_length += model.length_trajectories(trajectories).item()\n",
    "            wasserstein2_distance += model.wasserstein2_distance(Y, trajectories)\n",
    "\n",
    "    return log_probability/samples, flow_length/samples, wasserstein2_distance/samples, b\n",
    "\n",
    "\"\"\"takes the path to a directory containing models as input and performs tests on all models in the directory. results are saved in test_log\"\"\"\n",
    "def test_models(models_dir: str):\n",
    "    models = [f for f in os.listdir(models_dir) if os.path.isfile(os.path.join(models_dir, f))]\n",
    "    log_path = \"/\".join(models_dir.split(\"/\")[:2]) + \"/training_log.txt\"\n",
    "    a = 0\n",
    "    with open(log_path, 'a') as test_file:\n",
    "        test_file.write(f\"\\ntests \\n\")\n",
    "        test_file.write(\"negative log-likelihood, flow length, wasserstein2 distance \\n\")\n",
    "        for model in models:\n",
    "            model_path = os.path.join(models_dir, model)\n",
    "            log_likelihood, flow_length, wasserstein2, batch = test_model(model_path)\n",
    "            test_file.write(batch + f\": {log_likelihood}, {flow_length}, {wasserstein2} \\n\")\n",
    "\n",
    "\n",
    "\"\"\"saves the model and the plots of the trajectories of the generated samples and updates the metrics at the current batch\"\"\"\n",
    "def save(model: torch.nn.Module, trajectories: torch.Tensor, metrics: dict, X, Y, loss, batch, elapsed_time, args):\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(args.parameter_path + \"/models\", \"batch_\"+f\"{batch}_model.pt\"))         #saves the model\n",
    "\n",
    "    fig, ax = model.plot_trajectories(trajectories)\n",
    "    ax.set_title(f\"{args.model_type}_{args.initial_dataset}_to_\" + f\"{args.target_dataset}\")\n",
    "\n",
    "    fig.savefig(os.path.join(args.parameter_path + \"/trajectories\", \"batch_\"+f\"{batch}_trajectory.png\"))                #saves the plot of the trajectories\n",
    "    \n",
    "    metrics[\"batches\"].append(batch)\n",
    "    metrics[\"log_probability\"].append(model.log_probability(torch.linspace(0, 1, 5).type(torch.float32), Y))\n",
    "    metrics[\"loss\"].append(loss)\n",
    "    metrics[\"flow_length\"].append(model.length_trajectories(trajectories))\n",
    "    metrics[\"wasserstein2_distance\"].append(model.wasserstein2_distance(Y, trajectories))\n",
    "    metrics[\"elapsed_time\"].append(elapsed_time)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\"\"\"Dynamics, i.e., right hand side of the ODE\"\"\"\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim=2, out_dim=None, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        if out_dim is None:\n",
    "            out_dim = in_dim\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_dim + 1, hidden_dim),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Linear(hidden_dim, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        if t.dim()==0:\n",
    "            t = t.expand(x.size(0),)\n",
    "        x = torch.cat((x, t[:,None]),dim=-1) \n",
    "        return self.net(x)\n",
    "    \n",
    "    \"\"\"plots the ode solutions from its initial value x at time 0 to the final solution at time 1 (t decides number of steps)\"\"\"\n",
    "    def plot_trajectories(self, trajectories=None, t=None, x=None):\n",
    "        fig, ax = plt.subplots()\n",
    "        with torch.no_grad():\n",
    "            if trajectories == None:\n",
    "                trajectories = odeint(self, x, t, method=\"rk4\")\n",
    "\n",
    "            ax.plot(trajectories[:,:,0], trajectories[:,:,1], color=\"silver\", alpha=.7, zorder=0, label=\"flow\")            \n",
    "            ax.scatter(trajectories[0,:,0],trajectories[0,:,1], c=\"royalblue\", s=1, label=\"prior sample\", zorder=1)\n",
    "            ax.scatter(trajectories[-1,:,0], trajectories[-1,:,1], c=\"darkorange\", s=1, label=\"gen sample\", zorder=1)\n",
    "\n",
    "            handles, labels = plt.gca().get_legend_handles_labels()\n",
    "            by_label = dict(zip(labels, handles))\n",
    "            plt.legend(by_label.values(), by_label.keys())\n",
    "        \n",
    "        return fig, ax\n",
    "    \n",
    "    \"\"\"log probability of the model with a normal gaussian as the initial distribution, esto esta mal luego pregunta\"\"\"\n",
    "    def log_probability(self, t, x):\n",
    "        initial_distr = torch.distributions.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    "\n",
    "        l0 = torch.zeros((x.size(0),1), requires_grad=False)\n",
    "        initial_values = (x, l0)\n",
    "\n",
    "        augmented_dynamics = Augmented_ODE(self)\n",
    "\n",
    "        z_t, log_det = odeint(augmented_dynamics, initial_values, t, method=\"rk4\")\n",
    "\n",
    "        logp_x = initial_distr.log_prob(z_t[-1]) + log_det[-1]\n",
    "\n",
    "        return -logp_x.mean()\n",
    "    \n",
    "    \"\"\"computes the average length of the trajectories from the initial values x to the values at the final timestep\"\"\"\n",
    "    def length_trajectories(self, trajectories=None, t=None, x=None):\n",
    "        with torch.no_grad():\n",
    "            if trajectories == None:\n",
    "                trajectories = odeint(self, x, t, method=\"rk4\")\n",
    "            distances = torch.linalg.norm(trajectories[1:] - trajectories[:-1], dim=-1)\n",
    "            length = distances.sum(dim=0)\n",
    "\n",
    "            return length.mean()\n",
    "        \n",
    "    \"computes the Wasserstein2 distance between samples generated from the initial values x and samples y from the true distribution\"\n",
    "    def wasserstein2_distance(self, y, trajectories=None, t=None, x=None):\n",
    "        with torch.no_grad():\n",
    "            if trajectories == None:\n",
    "                trajectories = odeint(self, x, t, method=\"rk4\")\n",
    "            z = trajectories[-1]\n",
    "            a, b = ot.unif(z.size(0)), ot.unif(y.size(0))\n",
    "            cost = torch.cdist(z, y) ** 2\n",
    "            distance = ot.emd2(a, b, cost.numpy())\n",
    "\n",
    "            return distance**.5\n",
    "\n",
    "    \n",
    "\"\"\"Augmented ODE for CNF without any regularization and choice of samples for the Hutchinson trace estimator\"\"\"\n",
    "class Augmented_ODE(nn.Module):\n",
    "    def __init__(self, ode_func: nn.Module):\n",
    "        super().__init__()\n",
    "        self.odefunc = ode_func\n",
    "\n",
    "    def forward(self, t, states):\n",
    "        with torch.no_grad():\n",
    "            z = states[0]\n",
    "            dz_dt, dlogp_z_dt =  self.hutchinson_trace_estimator(t, z)\n",
    "            return (dz_dt, dlogp_z_dt)\n",
    "        \n",
    "    def hutchinson_trace_estimator(self, t, z, samples=20):\n",
    "        trace = 0\n",
    "        \n",
    "        for _ in range(samples):\n",
    "            epsilon = torch.randn_like(z)\n",
    "            output_f, vjp_f = torch.autograd.functional.vjp(self.odefunc, (t,z), v=epsilon, create_graph=True)\n",
    "            trace +=  (vjp_f[1]*epsilon).sum(1).unsqueeze(1)    \n",
    "\n",
    "        return output_f, trace/samples\n",
    "\n",
    "\"\"\"Augmented ODE to train RNODE\"\"\"\n",
    "class regularized_Augmented_ODE(nn.Module):\n",
    "    def __init__(self, ode_func: nn.Module):\n",
    "        super().__init__()\n",
    "        self.odefunc = ode_func\n",
    "\n",
    "    def forward(self, t, states):\n",
    "        with torch.set_grad_enabled(True):\n",
    "            z = states[0]                                                               #dynamics \n",
    "            dz_dt, vjp_f, epsilon = self.vjp(self.odefunc, t, z)\n",
    "            dlog_det_dt =  (vjp_f*epsilon).sum(1).unsqueeze(1)                           #log-det of the Jacobian   \n",
    "            dE_dt = (torch.linalg.vector_norm(dz_dt, dim=1, keepdims=True)**2)          #kinetic Energy\n",
    "            dn_dt = (torch.linalg.vector_norm(vjp_f, dim=1, keepdims=True)**2)          #Frobenius norm of the Jacobian\n",
    "            return (dz_dt, dlog_det_dt, dE_dt, dn_dt)\n",
    "\n",
    "    def vjp(self, f, t, z):\n",
    "        \"\"\"computes vector Jacobian product and returns (output of the function, vjp, epsilon)\"\"\"\n",
    "        epsilon = torch.randn_like(z)\n",
    "        output_f, vjp_f = torch.autograd.functional.vjp(f, (t,z), v=epsilon, create_graph=True)\n",
    "        return output_f, vjp_f[1], epsilon\n",
    "\n",
    "\n",
    "\"\"\"Helper class to sample and compute the OT plan, as well as the conditional location and flow\"\"\"\n",
    "def padding(t, x):\n",
    "    if isinstance(t, (float, int)):\n",
    "        return t\n",
    "    return t.view([x.size(0)] + [1] * (x.dim() - 1))\n",
    "\n",
    "class Conditional_FM():\n",
    "    def __init__(self, sigma=0):\n",
    "        self.ot_solver = ot.emd\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def get_map(self, x0, x1):\n",
    "        a, b = ot.unif(x0.size(0)), ot.unif(x1.size(0))\n",
    "        cost = torch.cdist(x0, x1) ** 2\n",
    "        pi = self.ot_solver(a, b, cost.numpy())\n",
    "\n",
    "        return pi\n",
    "    \n",
    "    def sample_OT(self, x0, x1, batch_size: int):\n",
    "        pi = self.get_map(x0, x1)\n",
    "        p = pi.flatten()\n",
    "        p = p / p.sum()\n",
    "        choices = np.random.choice(\n",
    "            pi.shape[0] * pi.shape[1], p=p, size=batch_size)\n",
    "        i, j = np.divmod(choices, pi.shape[1])\n",
    "    \n",
    "        return x0[i], x1[j]  \n",
    "    \n",
    "    def sample_location_and_conditional_flow(self, x0, x1):\n",
    "        t = torch.rand(x0.shape[0]).type_as(x0)\n",
    "        var = torch.randn_like(x0)\n",
    "        padded_t = padding(t, x0)\n",
    "        sigma_t = padding(self.sigma, x0)\n",
    "        xt = padded_t * x1 + (1 - padded_t) * x0 +  sigma_t * var\n",
    "        ut = x1 - x0\n",
    "\n",
    "        return t, xt, ut  \n",
    "    \n",
    "    \n",
    "\"\"\"computes the loss of RNODE, given the dynamics 'model' and samples 'x'\"\"\"\n",
    "def rnode_loss(model: torch.nn.Module, x, args):\n",
    "    initial_distr = torch.distributions.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    "    t = torch.linspace(0, 1, 5).type(torch.float32)\n",
    "    l0 = torch.zeros((x.size(0),1), requires_grad=True)\n",
    "    kin_E0 = torch.zeros((x.size(0),1), requires_grad=True)\n",
    "    n0 = torch.zeros((x.size(0),1), requires_grad=True)\n",
    "    initial_values = (x, l0, kin_E0, n0)\n",
    "\n",
    "    augmented_dynamics = regularized_Augmented_ODE(model)\n",
    "\n",
    "    z_t, log_det, E_t, n_t = odeint(augmented_dynamics, initial_values, t,\n",
    "                                    method=args.odeint_method,\n",
    "                                    atol=args.odeint_atol,\n",
    "                                    rtol=args.odeint_rtol)\n",
    "\n",
    "    z1, l1, kin_E1, n1 = z_t[-1], log_det[-1], E_t[-1], n_t[-1]\n",
    "\n",
    "    logp_x = initial_distr.log_prob(z1) + l1 -args.reg_kinetic_energy * kin_E1 - args.reg_frobenius_norm * n1\n",
    "    loss = -logp_x.mean()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "\"\"\"computes the loss of CFM given the dynamics 'model', initial and target samples 'x0' and 'x1' respectively and batch size 'bs'\"\"\"\n",
    "def cfm_loss(model: torch.nn.Module, x0, x1, bs):           #change order of x0 and x1 to obtain target at time 0 and initial at time 1\n",
    "    flow_matcher = Conditional_FM()\n",
    "    x0, x1 = flow_matcher.sample_OT(x0, x1, bs) \n",
    "    t, xt, ut = flow_matcher.sample_location_and_conditional_flow(x0, x1)\n",
    "    \n",
    "    loss = torch.mean((model(t,xt) - ut)**2)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "\"\"\"Training loop for RNODE\"\"\"\n",
    "def rnode_training(args, metrics):\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    model = MLP()\n",
    "\n",
    "    initial_samples = sampler(\"normal\")\n",
    "    target_samples = sampler(args.target_dataset)\n",
    "\n",
    "    X = initial_samples(1000)\n",
    "    Y = target_samples(1000)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    model.train()\n",
    "    batch_save = int(args.num_batches/20)\n",
    "    batch_loss = 0\n",
    "    \n",
    "    start = time.time()\n",
    "    for i in tqdm(range(1, args.num_batches+1), desc=\"Training Batches\"):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x = target_samples(args.batch_size)\n",
    "        x.requires_grad = True\n",
    "\n",
    "        loss = rnode_loss(model, x, args)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss += loss\n",
    "\n",
    "        if i == 1:\n",
    "            fig, ax = initial_setup(X, Y)\n",
    "            fig.savefig(os.path.join(args.parameter_path + \"/trajectories\", \"initial_target_distr.png\"))\n",
    "\n",
    "        elif i%batch_save == 0:\n",
    "            end = time.time()\n",
    "            elapsed_time = end-start\n",
    "\n",
    "            loss = batch_loss/batch_save\n",
    "            batch_loss = 0\n",
    "            print(f\"\\nbatch {i}, Loss: {loss}\")\n",
    "\n",
    "            trajectories = odeint(model, X, torch.linspace(1, 0, 100).type(torch.float32), method=\"rk4\")\n",
    "            metrics = save(model, trajectories, metrics, X, Y, loss, i, elapsed_time, args)\n",
    "            start = time.time()\n",
    "            plt.close('all')\n",
    "\n",
    "\n",
    "    print(\"finished training\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\"\"\"Training loop for OT-CFM\"\"\"\n",
    "def cfm_training(args, metrics):\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    model = MLP()\n",
    "\n",
    "    initial_samples = sampler(args.initial_dataset)\n",
    "    target_samples = sampler(args.target_dataset)\n",
    "\n",
    "    X = initial_samples(1000)\n",
    "    Y = target_samples(1000)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    model.train()\n",
    "    bs = args.batch_size\n",
    "    batch_save = int(args.num_batches/5)\n",
    "    batch_loss = 0\n",
    "\n",
    "    start = time.time()\n",
    "    for i in tqdm(range(1, args.num_batches+1), desc=\"Training Batches\"):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x0, x1 = initial_samples(bs), target_samples(bs)\n",
    "\n",
    "        loss = cfm_loss(model, x1, x0, bs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss += loss\n",
    "\n",
    "        if i == 1:\n",
    "            fig, ax = initial_setup(X, Y)\n",
    "            fig.savefig(os.path.join(args.parameter_path + \"/trajectories\", \"initial_target_distr.png\"))\n",
    "\n",
    "        elif i%batch_save == 0:\n",
    "            end = time.time()\n",
    "            elapsed_time = end-start\n",
    "            loss = batch_loss/batch_save\n",
    "            batch_loss = 0\n",
    "            print(f\"batch {i}, Loss: {loss}\")\n",
    "\n",
    "            trajectories = odeint(model, X, torch.linspace(1, 0, 100).type(torch.float32), method=\"rk4\")\n",
    "            metrics = save(model, trajectories, metrics, X, Y, loss, i, elapsed_time, args)      \n",
    "            start = time.time()\n",
    "            plt.close('all')\n",
    "\n",
    "    print(\"finished training\")\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\"\"\"combined training loop for rnode and cfm (if you want 'node+cfm' just set regularization constants to 0)\"\"\"\n",
    "def combined_training(args, metrics):\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    model = MLP()\n",
    "\n",
    "    initial_samples = sampler(args.initial_dataset)\n",
    "    target_samples = sampler(args.target_dataset)\n",
    "\n",
    "    X = initial_samples(1000)\n",
    "    Y = target_samples(1000)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    model.train()\n",
    "\n",
    "    batch_save = int(args.num_batches/5)\n",
    "    batch_loss = 0\n",
    "\n",
    "    start = time.time()\n",
    "    for i in tqdm(range(1, args.num_batches+1), desc=\"Training Batches\"):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x0, x1 = initial_samples(args.batch_size), target_samples(args.batch_size)\n",
    "\n",
    "        loss_cfm = cfm_loss(model, x1, x0, args.batch_size)\n",
    "        loss_rnode = rnode_loss(model, x1, args)\n",
    "        loss = args.cfm_loss_coefficient * loss_cfm + args.rnode_loss_coefficient * loss_rnode\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss += loss\n",
    "\n",
    "        if i == 1:\n",
    "            fig, ax = initial_setup(X, Y)\n",
    "            fig.savefig(os.path.join(args.parameter_path + \"/trajectories\", \"initial_target_distr.png\"))\n",
    "\n",
    "        elif i%batch_save == 0:\n",
    "            end = time.time()\n",
    "            elapsed_time = end-start\n",
    "            loss = batch_loss/batch_save\n",
    "            batch_loss = 0\n",
    "            print(f\"batch {i}, Loss: {loss}\")\n",
    "            \n",
    "            trajectories = odeint(model, X, torch.linspace(1, 0, 100).type(torch.float32), method=\"rk4\")\n",
    "            metrics = save(model, trajectories, metrics, X, Y, loss, i, elapsed_time, args)       \n",
    "            start = time.time()  \n",
    "            plt.close('all')\n",
    "            \n",
    "    print(\"finished training\")\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model_type: str): #choices: \"cfm\" or \"rnode\"\n",
    "    args = argparse.Namespace(\n",
    "        model_type=model_type,\n",
    "        initial_dataset=\"normal\",\n",
    "        target_dataset=\"moons\",\n",
    "        num_batches=10000,\n",
    "        batch_size=200,\n",
    "        learning_rate=1e-3,\n",
    "        parameter_path=\"C:/\",\n",
    "        odeint_method=\"rk4\",\n",
    "        odeint_rtol=1e-3,\n",
    "        odeint_atol=1e-3,\n",
    "        reg_kinetic_energy=.1,\n",
    "        reg_frobenius_norm=.1,\n",
    "        seed=44,\n",
    "        sigma = 0,\n",
    "        rnode_loss_coefficient=1,\n",
    "        cfm_loss_coefficient=1\n",
    "    )\n",
    "\n",
    "    print(\"Args parsed!\", flush=True)\n",
    "    print(f\"Args: {args}\", flush=True)\n",
    "\n",
    "    hyperparameters = {\n",
    "    \"model_type\": args.model_type,\n",
    "    \"learning_rate\": args.learning_rate,\n",
    "    \"batch_size\": args.batch_size,\n",
    "    \"num_batches\": args.num_batches,\n",
    "    \"odeint_method\": args.odeint_method,\n",
    "    \"seed\": args.seed}\n",
    "\n",
    "    metrics = {\n",
    "    \"batches\": [],\n",
    "    \"loss\": [],\n",
    "    \"log_probability\": [],\n",
    "    \"flow_length\": [],\n",
    "    \"wasserstein2_distance\": [],\n",
    "    \"elapsed_time\": []}\n",
    "\n",
    "\n",
    "    if args.model_type == \"rnode\":\n",
    "        args.parameter_path = args.parameter_path + f\"{args.model_type}_to_\" + f\"{args.target_dataset}_kin\" + f\"{args.reg_kinetic_energy}_frob\" + f\"{args.reg_frobenius_norm}\" \n",
    "        Path(os.path.join(args.parameter_path, \"trajectories\")).mkdir(parents=True, exist_ok=True)\n",
    "        Path(os.path.join(args.parameter_path, \"models\")).mkdir(parents=True, exist_ok=True)\n",
    "        hyperparameters[\"kinetic_regularization\"] = args.reg_kinetic_energy\n",
    "        hyperparameters[\"frobenius_regularization\"] = args.reg_frobenius_norm\n",
    "        metrics = rnode_training(args, metrics)\n",
    "\n",
    "    elif args.model_type == \"cfm\":\n",
    "        args.parameter_path = args.parameter_path + f\"{args.model_type}_{args.initial_dataset}_to_\" + f\"{args.target_dataset}_sigma\"+ f\"{args.sigma}\"\n",
    "        Path(os.path.join(args.parameter_path, \"trajectories\")).mkdir(parents=True, exist_ok=True)\n",
    "        Path(os.path.join(args.parameter_path, \"models\")).mkdir(parents=True, exist_ok=True)\n",
    "        hyperparameters[\"sigma\"] = args.sigma\n",
    "        metrics = cfm_training(args, metrics)\n",
    "\n",
    "    else:\n",
    "        args.parameter_path = args.parameter_path + f\"{args.model_type}_{args.initial_dataset}_to_\" + f\"{args.target_dataset}_rnode\"+ f\"{args.rnode_loss_coefficient}_cfm\" + f\"{args.cfm_loss_coefficient}\"\n",
    "        Path(os.path.join(args.parameter_path, \"trajectories\")).mkdir(parents=True, exist_ok=True)\n",
    "        Path(os.path.join(args.parameter_path, \"models\")).mkdir(parents=True, exist_ok=True)\n",
    "        hyperparameters[\"kinetic_regularization\"] = args.reg_kinetic_energy\n",
    "        hyperparameters[\"frobenius_regularization\"] = args.reg_frobenius_norm\n",
    "        hyperparameters[\"sigma\"] = args.sigma\n",
    "        hyperparameters[\"rnode_loss_coefficient\"] = args.rnode_loss_coefficient\n",
    "        hyperparameters[\"cfm_loss_coefficient\"] = args.cfm_loss_coefficient\n",
    "        metrics = combined_training(args, metrics)\n",
    "\n",
    "\n",
    "    save_hyperparameters_and_metrics(os.path.join(args.parameter_path, \"training_log.txt\"), hyperparameters, metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args parsed!\n",
      "Args: Namespace(model_type='rnode', initial_dataset='normal', target_dataset='moons', num_batches=1000, batch_size=256, learning_rate=0.001, parameter_path='C:/', odeint_method='rk4', odeint_rtol=0.001, odeint_atol=0.001, reg_kinetic_energy=0.1, reg_frobenius_norm=0.1, seed=44, sigma=0, rnode_loss_coefficient=1, cfm_loss_coefficient=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   5%|‚ñç         | 49/1000 [00:05<01:56,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch 50, Loss: 5.593203067779541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrnode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 47\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model_type)\u001b[0m\n\u001b[1;32m     45\u001b[0m     hyperparameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkinetic_regularization\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mreg_kinetic_energy\n\u001b[1;32m     46\u001b[0m     hyperparameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrobenius_regularization\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mreg_frobenius_norm\n\u001b[0;32m---> 47\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43mrnode_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcfm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     50\u001b[0m     args\u001b[38;5;241m.\u001b[39mparameter_path \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mparameter_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39minitial_dataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_to_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mtarget_dataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_sigma\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39msigma\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[17], line 372\u001b[0m, in \u001b[0;36mrnode_training\u001b[0;34m(args, metrics)\u001b[0m\n\u001b[1;32m    369\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mbatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 372\u001b[0m trajectories \u001b[38;5;241m=\u001b[39m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrk4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m metrics \u001b[38;5;241m=\u001b[39m save(model, trajectories, metrics, X, Y, loss, i, elapsed_time, args)\n\u001b[1;32m    374\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torchdiffeq/_impl/adjoint.py:206\u001b[0m, in \u001b[0;36modeint_adjoint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn, adjoint_rtol, adjoint_atol, adjoint_method, adjoint_options, adjoint_params)\u001b[0m\n\u001b[1;32m    203\u001b[0m state_norm \u001b[38;5;241m=\u001b[39m options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    204\u001b[0m handle_adjoint_norm_(adjoint_options, shapes, state_norm)\n\u001b[0;32m--> 206\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mOdeintAdjointMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjoint_rtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjoint_atol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m                                \u001b[49m\u001b[43madjoint_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjoint_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madjoint_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     solution \u001b[38;5;241m=\u001b[39m ans\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/autograd/function.py:598\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    602\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torchdiffeq/_impl/adjoint.py:24\u001b[0m, in \u001b[0;36mOdeintAdjointMethod.forward\u001b[0;34m(ctx, shapes, func, y0, t, rtol, atol, method, options, event_fn, adjoint_rtol, adjoint_atol, adjoint_method, adjoint_options, t_requires_grad, *adjoint_params)\u001b[0m\n\u001b[1;32m     21\u001b[0m ctx\u001b[38;5;241m.\u001b[39mevent_mode \u001b[38;5;241m=\u001b[39m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 24\u001b[0m     ans \u001b[38;5;241m=\u001b[39m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevent_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m         y \u001b[38;5;241m=\u001b[39m ans\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torchdiffeq/_impl/odeint.py:79\u001b[0m, in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     76\u001b[0m solver \u001b[38;5;241m=\u001b[39m SOLVERS[method](func\u001b[38;5;241m=\u001b[39mfunc, y0\u001b[38;5;241m=\u001b[39my0, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     solution \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     event_t, solution \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mintegrate_until_event(t[\u001b[38;5;241m0\u001b[39m], event_fn)\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torchdiffeq/_impl/solvers.py:114\u001b[0m, in \u001b[0;36mFixedGridODESolver.integrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    112\u001b[0m dt \u001b[38;5;241m=\u001b[39m t1 \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\u001b[38;5;241m.\u001b[39mcallback_step(t0, y0, dt)\n\u001b[0;32m--> 114\u001b[0m dy, f0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m y1 \u001b[38;5;241m=\u001b[39m y0 \u001b[38;5;241m+\u001b[39m dy\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m j \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(t) \u001b[38;5;129;01mand\u001b[39;00m t1 \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m t[j]:\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torchdiffeq/_impl/fixed_grid.py:29\u001b[0m, in \u001b[0;36mRK4._step_func\u001b[0;34m(self, func, t0, dt, t1, y0)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_step_func\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, t0, dt, t1, y0):\n\u001b[1;32m     28\u001b[0m     f0 \u001b[38;5;241m=\u001b[39m func(t0, y0, perturb\u001b[38;5;241m=\u001b[39mPerturb\u001b[38;5;241m.\u001b[39mNEXT \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperturb \u001b[38;5;28;01melse\u001b[39;00m Perturb\u001b[38;5;241m.\u001b[39mNONE)\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrk4_alt_step_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperturb\u001b[49m\u001b[43m)\u001b[49m, f0\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torchdiffeq/_impl/rk_common.py:114\u001b[0m, in \u001b[0;36mrk4_alt_step_func\u001b[0;34m(func, t0, dt, t1, y0, f0, perturb)\u001b[0m\n\u001b[1;32m    112\u001b[0m     k1 \u001b[38;5;241m=\u001b[39m func(t0, y0, perturb\u001b[38;5;241m=\u001b[39mPerturb\u001b[38;5;241m.\u001b[39mNEXT \u001b[38;5;28;01mif\u001b[39;00m perturb \u001b[38;5;28;01melse\u001b[39;00m Perturb\u001b[38;5;241m.\u001b[39mNONE)\n\u001b[1;32m    113\u001b[0m k2 \u001b[38;5;241m=\u001b[39m func(t0 \u001b[38;5;241m+\u001b[39m dt \u001b[38;5;241m*\u001b[39m _one_third, y0 \u001b[38;5;241m+\u001b[39m dt \u001b[38;5;241m*\u001b[39m k1 \u001b[38;5;241m*\u001b[39m _one_third)\n\u001b[0;32m--> 114\u001b[0m k3 \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_two_thirds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mk2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_one_third\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m k4 \u001b[38;5;241m=\u001b[39m func(t1, y0 \u001b[38;5;241m+\u001b[39m dt \u001b[38;5;241m*\u001b[39m (k1 \u001b[38;5;241m-\u001b[39m k2 \u001b[38;5;241m+\u001b[39m k3), perturb\u001b[38;5;241m=\u001b[39mPerturb\u001b[38;5;241m.\u001b[39mPREV \u001b[38;5;28;01mif\u001b[39;00m perturb \u001b[38;5;28;01melse\u001b[39;00m Perturb\u001b[38;5;241m.\u001b[39mNONE)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (k1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m (k2 \u001b[38;5;241m+\u001b[39m k3) \u001b[38;5;241m+\u001b[39m k4) \u001b[38;5;241m*\u001b[39m dt \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.125\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torchdiffeq/_impl/misc.py:197\u001b[0m, in \u001b[0;36m_PerturbFunc.forward\u001b[0;34m(self, t, y, perturb)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Do nothing.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torchdiffeq/_impl/misc.py:197\u001b[0m, in \u001b[0;36m_PerturbFunc.forward\u001b[0;34m(self, t, y, perturb)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Do nothing.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torchdiffeq/_impl/misc.py:165\u001b[0m, in \u001b[0;36m_ReverseFunc.forward\u001b[0;34m(self, t, y)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, t, y):\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmul \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 154\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, t, x)\u001b[0m\n\u001b[1;32m    152\u001b[0m     t \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mexpand(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),)\n\u001b[1;32m    153\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x, t[:,\u001b[38;5;28;01mNone\u001b[39;00m]),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Jupyter/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training(\"rnode\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
